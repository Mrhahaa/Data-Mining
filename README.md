**专业：**计算机技术

**姓名：**张静杰

**学号：**92342201

## Github上传作业

**Github个人仓库地址：**https://github.com/Mrhahaa/Data-Mining

### 流程

1. 注册个人github账号

   ![26c31b4b1d039d82b3a25be1f51e5be](assets/26c31b4b1d039d82b3a25be1f51e5be.png)

2. 登录个人github账号

   ![ada04893c9bd6ca8dca6fb05ff9cf33](assets/ada04893c9bd6ca8dca6fb05ff9cf33.png)

3. 建立一个仓库命名为Data Mining

   ![image-20240426212614944](assets/image-20240426212614944.png)

4. 上传自己的PPT到Data Mining中

   <img src="C:\Users\whd123\AppData\Roaming\Typora\typora-user-images\image-20240426163257849.png" alt="image-20240426163257849" style="zoom:33%;" />



# **想获得的计算机技能**——利用图卷积神经网络（GCN、ST-GCN++）进行骨骼识别

## 一、图卷积神经网络的学习总结

### 1. 图卷积神经网络的来源

#### 1.1 问题发现

传统CNN和RNN在处理某些特定类型数据时存在局限性，特别是在面对具有复杂**图结构**的数据时，表现不佳。

#### 1.2 CNN的局限性

- **核心原理**：卷积核(kernel)在图像上滑动并通过卷积操作提取特征，其有效性基于图像数据的**平移不变性**。无论卷积核在图像的哪个位置，其内部结构保持一致，从而实现参数共享。

#### 1.3 RNN的优势

- **应用场景**：针对自然语言等一维序列信息，通过循环单元和各类门控机制，RNN能够捕捉序列前后信息的依赖关系，从而提取序列特征。

#### 1.4 共同点与局限性

- **共同局限**：CNN和RNN在处理规则的欧式空间数据时表现出色，但这类方法在面对非规则结构的数据时面临挑战。

#### 1.5 图结构数据问题

- **实际问题**：现实世界中广泛存在不规则的**图结构数据**，例如社交网络、化学分子结构、知识图谱等。甚至在二维图像的目标识别中，关注的关键点及其相互联系也可构成一种图结构。
- **挑战**：图结构不具备平移不变性，每个节点的邻域结构可能是独一无二的，是一种无限维的数据形态。因此，传统的CNN和RNN在这种情况下难以有效地发挥作用，因为它们无法适应图结构数据的高度复杂性和不规则性。这也促成了图卷积神经网络（Graph Convolutional Neural Networks, GCNs）的研究与发展。

 

### 2. 图卷积神经网络的作用

- 类似于CNN，图卷积神经网络（GCN）同样作为一个高效的**特征提取器**，专门针对图结构数据设计。

- **功能概述**：GCN创新性地提供了一种从图数据中抽取特征的方法，通过这种方法，可以运用提取出的特征完成多项任务，包括但不限于：
  - **节点分类**：对图中各个节点进行分类预测；
  - **图分类**：对整个图结构进行分类；
  - **边预测**：预测图中边的存在与否或者其他属性；
  - **图嵌入表示**：将图转化为低维向量表示，便于后续分析或与其他模型结合使用。

![image-20240426232344043](assets/image-20240426232344043.png) 

### 3. 图卷积神经网络的原理

#### **3.1 原理解释：**

- **核心概念**：图卷积利用图中其他节点的信息来推导目标节点的信息。在图中，节点的状态不断受到邻居节点及更远节点的影响，直至达到某种平衡状态，邻近节点的影响权重更大。

- **节点与结构特征**：图数据具有节点特征（每个节点带有自身的特征属性）和结构特征（节点间的连接关系体现为边）。因此，在处理图数据时，必须兼顾节点特性和结构信息。

- **图卷积核心**：图卷积的核心在于利用**边的信息**对**节点特征信息**进行整合更新，生成新的节点表征。其根本目的是**提取图数据的拓扑空间特征**。

#### **3.2 两种理解流派：**

- **基于频谱的方法**：
  - 主要包括Spectral CNN、第二代GCN、ChebyNet、CayleyNet、一阶ChebyNet等。其中，ChebyNet及其一阶近似在行为识别等领域得到广泛应用。

- **基于空间的方法**：
  - 包括消息传递与聚合、图采样与聚合、图结构序列化、注意力机制下的卷积、关注感知域等多种方法。

#### **3.3 GCN方法类型比较：**

**(1) 基于频谱的图卷积网络**：

   - 是将图信号转换到频谱域进行分析后再回归至空域，以实现图信号的降噪与特征提取。此类方法通过添加自连接单元和归一化邻接矩阵改善了基于空间方法忽视节点自身特征以及邻接矩阵规模过大的问题。但存在灵活性较差、普适性不强和运行效率低等不足。

**(2) 基于空间的图卷积方法**：

   - 利用邻域信息聚合的概念简化了复杂性，提升了泛化能力和运行效率，成为行为识别等领域处理图结构数据的基本思路。

#### **3.4 谱模型与空间模型对比：**

- **效率**：
  - 谱模型计算复杂度随图规模增大迅速增加，难以进行大规模图的并行处理和扩展。
  - 空间模型通过邻域节点聚合可有效处理大规模图，采用批量数据计算而非全图计算，且可通过GraphSage、LGCN等采样技术提升效率。

- **通用性**：
  - 谱模型对新图或不同图的泛化能力较弱，因为它假设图结构固定不变。
  - 空间模型则可在不同位置和结构间共享权重，具备更好的泛化性能。

- **灵活性**：
  - 谱模型仅适用于无向图，处理有向图需将其转换为无向图。
  - 空间模型更为灵活，可处理多种输入源，如边特征和方向。

#### **3.5 卷积本质：**

- **空域**：
  - 在图结构中，将节点的邻居节点特征传播至中心节点并加权求均值得到聚合特征，这一过程类似于常规卷积操作，实现拓扑结构上的信息传播。

- **频域**：
  - 应用图的拉普拉斯矩阵分解和傅里叶变换进行节点信息收集，通过谱域滤波器定义图卷积，从图信号处理角度去除噪声。

![image-20240426233017118](assets/image-20240426233017118.png)

#### **3.6 空间域优缺点**：

- **优点**：直接利用图的拓扑结构进行信息传播。
- **缺点**：
  - 层数加深时，节点聚合来自越来越远的特征，但这也可能导致信息传播范围过大。
  - 权重共享可能导致对图结构变化敏感。
  - 不同节点邻居数量差异可能造成聚合特征不均衡。
  - 需要特别设计机制确保节点自身特征纳入聚合计算。

​	尽管基于谱域的图卷积理论基础深厚且在某些场景中效果出色，但由于其复杂性、效率和灵活性的问题，近年来基于空间域的方法因其易扩展性和适用性更受青睐。

### 4. 图的概念说明

(1) 在图数据中，通常包含一组节点(node)，总共数量为N，每个节点都具有自身的特征属性。

(2) 图结构可以被表示为G=(V,E)，其中V代表图中所有节点的集合，E则代表边的集合，且图中节点总数为N。在处理图数据时，我们会关注三个核心的数学矩阵：

- 特征矩阵X：所有节点的特征信息以一个N×D维矩阵的形式存储，其中N为节点数，D为特征维度。

- 邻接矩阵A（Adjacency Matrix）：描述了图中各节点间的关系，是一个N×N维的矩阵，矩阵中A_ij的值表示节点i与节点j之间是否存在边及边的权重。

- 度矩阵D（Degree Matrix）：该矩阵是对角矩阵，其对角线上的元素Di,i等于节点i的度（即与其相连的其他节点的数量）：
  $$
  D_{ii} = \sum_j A_{ij}
  $$

![image-20240426234027435](assets/image-20240426234027435.png)
$$
A=\begin{pmatrix}0&1&0&1\\1&0&0&1\\0&0&0&1\\1&1&1&0\end{pmatrix}

\quad A=\begin{pmatrix}0&0&0&1\\1&0&0&0\\0&0&0&0\\0&1&1&0\end{pmatrix}
$$
在图卷积神经网络（GCN）中，通过应用如下公式可以有效提取图的节点特征：
$$
f\Big(H^{(l)},A\Big)=\sigma\Big(\hat{D}^{-\frac{1}{2}}\hat{A}\hat{D}^{-\frac{1}{2}}H^{(l)}W^{(l)}\Big)
$$

其中，$H^{(l)}$代表第l层的节点特征矩阵，$\hat{A}$是邻接矩阵经过标准化处理后的版本，$\hat{D}$是对角线元素为节点度修正后的矩阵，$W^{(l)}$是对应的权重矩阵，$\sigma$​代表激活函数。

![image-20240426233834566](assets/image-20240426233834566.png)

​	在整个GCN模型处理过程中，无论经过多少层的计算和特征变换，原始图中节点间的连接关系，即邻接矩阵A，始终是被共享并用于指导信息传递的。最终，GCN将输入图中的节点特征X转换为新的特征表示Z。 

### **5. 新特征**

#### **5.1 目标**

图网络的目标是从图的初始特征X出发，通过学习过程生成更抽象且融合了图中其他节点特征的新特征，这些新特征可用于节点分类或属性预测。数学表达形式为：
$$
H^{(k+1)}=f(H^{(k)},A)
$$
其中，k代表网络层数，$H^{(k)}$表示网络第k层的特征。

#### **5.2 提出**

一个简单的神经网络层可描述如下：

- 输入：邻接矩阵A和节点特征H；
- 执行内积运算；
- 乘以参数矩阵W；
- 应用激活函数，形成一个简易的神经网络层。

#### **5.3 步骤**

图网络的学习过程可细分为三个关键环节：

1. **变换（Transform）**：对当前节点特征进行变换学习，通常采用乘法规则（Wx）；
2. **聚合（Aggregate）**：聚合相邻节点特征以获得该节点的新特征，此处采用了简单的加法规则；
3. **激活（Activate）**：利用激活函数引入非线性。

​	权重在整个图中是共享的，类似于CNN中的参数共享；此外，随着网络层数增加，节点的感受野也会扩大，即节点特征逐渐融合更多信息。

![image-20240426231414584](assets/image-20240426231414584.png)

#### **5.4 图卷积**

原始加法规则存在的两个问题及解决方案如下：

- **未考虑自身特征问题**：解决办法是在邻接矩阵A中添加单位矩阵I，即 $\tilde{A}=A+I_N$；
- **节点度影响问题**：为了避免度大节点特征过大或度小节点特征过小导致的梯度爆炸或消失问题，可以通过对邻接矩阵进行归一化处理，即乘以经过更新后的度矩阵的逆矩阵，得到 $\tilde{D}^{-1}\tilde{A}$。

改进后的图卷积表达式为：
$$
H^{(k+1)}=f(H^{(k)},A)=\sigma(\tilde{D}^{-1}\tilde{A}H^{(k)}W^{(k)})
$$
并且，通过对领域节点特征求平均而非求和，解决了原有问题。进一步地，提出了对称归一化的聚合操作，即谱图卷积方法：
$$
H^{(k+1)}=f(H^{(k)},A)=\sigma(\tilde{D}^{-0.5}\tilde{A}\tilde{D}^{-0.5}H^{(k)}W^{(k)})
$$
这一方法在聚合邻居节点特征时不仅考虑了节点i的度数，还考虑了邻居节点j的度数。

![image-20240426231607285](assets/image-20240426231607285.png)

#### **5.5 分类**

图神经网络（GNN）是一个包含多种类型的大家族，其中GCN只是谱图卷积的一个分支。GNN可以从图类型、传播类型和训练方法三个方面进行分类。在传播类型中，包括卷积、注意力机制、门机制和跳跃连接等。

![image-20240426231624159](assets/image-20240426231624159.png)

#### **5.6 特点**

- GCN是对卷积神经网络在图领域上的自然推广，能够同时学习节点特征信息和结构信息，是目前处理图数据学习任务的理想选择；
- 适用于任意拓扑结构的节点和图；
- 在节点分类和边预测等任务中，相比于其他方法，在公开数据集上表现出色；
- 即使不进行训练，仅使用随机初始化的参数W，GCN也能提取出有意义的特征。

#### **5.7 常见问题**

1. 如果没有节点特征，是否可以使用GCN？
   - 可以，对于无特征的网络，可以用单位矩阵I替换特征矩阵X。
2. 没有任何节点类别标注或其他标注信息时能否使用GCN？
   - 可以，未经训练的GCN仍可用于提取graph embedding，并且效果尚可。
3. GCN网络的最优层数是多少？
   - 根据相关研究，在某些实验中发现GCN的层数不宜过多，通常2-3层即可达到较好的效果。



## 二.  基于GCN、ST—GCN++ 对骨骼关键点进行动作识别

### 1. 视频数据的不同模态

#### 1.1 视频模态概述

![在这里插入图片描述](file://C:\Users\Lenovo\Desktop\assets\3725000f6e7d49e898cec241941e6dd0.gif?lastModify=1714142932)

- **RGB图像**：广泛应用，包含丰富信息，可衍生出Flow和Skeleton数据，但处理此类数据需较大的计算资源。

- **Flow（光流）**：主要体现视频中的运动信息，处理方式与RGB类似，常采用3D卷积操作。

- **Audio（音频）**：在动作识别中使用不广泛。

- **Skeleton（骨骼）**：由人体关键点序列组成，其坐标信息与动作识别紧密相关，拥有较高的信息密度。

### 2. 骨骼动作识别的内涵、条件及优势

#### 2.1 骨骼动作识别概念与特点

- **关键点坐标识别**：利用关键点坐标识别动作，如通过面部Landmarks识别表情或手部Landmarks识别手势。

- **识别前提**：
  - （1）动作应当可以通过Skeleton序列准确识别，若动作分类主要依据非肢体因素（例如区分吃不同食物的动作主要依赖食物而非肢体动作），则不适合仅凭骨骼数据识别。
  - （2）视频中须包含高质量的骨骼数据，即包含完整的人体并且大部分身体可见。

#### 2.2 适用场景与优点

- **解决数据稀缺问题**：在训练数据稀少或训练与测试数据间存在较大视觉偏差（如背景、环境变化导致RGB模型表现欠佳）时，骨骼动作识别模型因其仅依赖关键点坐标而具备更好的泛化能力。

- **轻量化处理**：相对于处理RGB数据，骨骼动作识别所需的计算量较小，适合作为轻量级动作识别任务的解决方案。

  | 方法类型         | RGB(3D—CNN)  | SKeleton(3D—CNN) | SKeleton(GCN) |
  | ---------------- | ------------ | ---------------- | ------------- |
  | 主干网络         | SlowOnly—R50 | SlowOnly—R50     | ST—GCN        |
  | 帧数             | 8            | 48               | 100           |
  | 输入大小         | 3×8×224×224  | 17×48×56×56      | 2×100×17×3    |
  | 参数量（Params） | 31.6M        | 2.0M             | 3.1M          |
  | 计算量（FLOPs）  | 42.2G        | 15.8G            | 3.8G          |

### 3. 获取Skeleton序列作为输入

#### 3.1 获取骨骼数据的方法

##### 3.1.1 Kinect Sensor（RGBD）

- 在构建RGBD数据集时，借助带有RGBD深度相机的Kinect传感器来估计3D骨骼信息。但由此得到的关键点坐标可能存在较多噪声，精度不高。

![image-20240426225025448](assets/image-20240426225025448.png)

##### 3.1.2 2D人体姿态估计

- 通过算法估计视频中的2D人体姿态关键点，并以此预测动作。

![image-20240426225043104](assets/image-20240426225043104.png)

##### 3.1.3 3D人体姿态估计——Motion Capture

- 利用专业运动捕捉设备（Motion Capture）获取3D骨骼数据，尽管这种方式在实际网络模型应用中较为少见。

  ![在这里插入图片描述](file://C:\Users\Lenovo\Desktop\assets\e4a96e82a46d40b2809c136ae2198e23.gif?lastModify=1714142932)

### 4. 基于GCN的技术路线——ST-GCN++

#### 4.1 GCN——骨骼关键点处理

##### 4.1.1 输入结构

- **GCN**（Graph Convolutional Network）将骨骼关键点序列作为输入，其输入形状为 T × V × C。

  - **T**：代表序列长度，即关键点的时间跨度。
  - **V**：表示一个骨架中关键点的数量。
  - **C**：特征维度，根据应用场景可能是2D或3D坐标。

- 当有多个人物时，GCN通常会对所有人的特征进行平均处理，形成整体的特征表示。

  ![image-20240426230116387](assets/image-20240426230116387.png)

##### 4.1.2 GCN网络结构

- GCN网络由多个GCN Block逐层堆叠而成，设计思路类似Bottleneck和ResNet，用于逐步提炼关键点特征。

#### 4.2 ST-GCN结构特点

- 随着网络层次的深入，特征的通道数（C）逐渐增加，而在时序维度（T）上则实施递归的降采样。

- 最后一层的输出通过全局平均池化（Global Average Pooling）生成最终的特征向量。

- 这些特征经过一个线性分类层后，即可得出动作分类的结果。

![image-20240426210222194](file://C:\Users\Lenovo\Desktop\assets\image-20240426210222194.png?lastModify=1714143733)

##### 4.2.1 GCN Block设计

- **GCN Block**包括一个GCN Layer和一个TCN Layer。

  - **GCN Layer**：利用系数矩阵A对同一帧内的各个关键点进行特征融合。

  - **TCN Layer**：运用1D卷积对单个关键点进行时序建模。

- **GCN Block的前向传播过程**：首先通过GCN Layer处理空间特征融合，然后通过TCN Layer完成时序特征建模。

```
def forward(self, x, A=None):
    # 将输入x经过GCN层（使用参数A）处理，然后通过TCN层，再与残差连接后的x相加
    # 这里包含了GCN Layer和TCN Layer的操作
    x = self.tcn(self.gcn(x, A)) + self.residual(x)
    
        # 最后，对结果进行ReLU激活函数处理
    return self.relu(x)
```

- **TCN Layer**：采用大小为9的大kernel的1D卷积操作，虽增加了计算量和参数量，但也增强了模型对于时序特征的学习能力。

```
# 定义一个名为unit_tcn的类，继承自nn.Module
class unit_tcn(nn.Module):
    def __init__(self,
                 in_channels,
                 out_channels,
                 kernel_size=9,
                 stride=1):
        # 调用父类nn.Module的初始化方法
        super(unit_tcn, self).__init__()

        # 计算并设置卷积层的填充值
        pad = (kernel_size - 1) // 2

        # 定义一个2D卷积层，其中时间维度上的卷积核大小为kernel_size，特征维度上的卷积核大小为1
        self.conv = nn.Conv2d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=(kernel_size, 1),
            padding=(pad, 0),
            stride=(stride, 1))

        # 定义一个针对输出通道的Batch Normalization层
        self.bn = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        # 在前向传播过程中，先通过Batch Normalization层，再通过定义的卷积层
        x = self.bn(self.conv(x))

        # 返回处理后的结果
        return x
```

- **GCN Layer**：

  - 利用系数矩阵A整合不同关键点之间的特征。
  - 系数矩阵A来源于两部分：预先设定的系数矩阵与根据数据动态生成的稀疏mask。

  ```
  # 定义一个名为unit_gcn的类，继承自nn.Module
  class unit_gcn(nn.Module):
      def __init__(self,
                   in_channels,
                   out_channels,
                   s_kernel=3):
          # 调用父类nn.Module的初始化方法
          super().__init__()
  
          # 设置局部卷积核大小
          self.s_kernel = s_kernel
  
          # 定义一个用于通道变换的1x1卷积层，输出通道数为out_channels乘以s_kernel
          self.conv = nn.Conv2d(in_channels, out_channels * s_kernel, kernel_size=1)
  
      def forward(self, x, A):
          # 检查系数矩阵A的尺寸是否满足要求，即其第0维大小应等于局部卷积核数量s_kernel
          assert A.size(0) == self.s_kernel  # 利用系数矩阵A对不同关键点进行特征融合
  
          # 对输入x进行1x1卷积操作
          x = self.conv(x)
  
          # 获取x的形状信息，分别为：批次数量、输出通道数、时间步长、顶点数
          n, kc, t, v = x.size()
  
          # 改变x的形状以适应矩阵运算，使得每个输出通道对应一组系数矩阵
          x = x.view(n, self.s_kernel, kc // self.s_kernel, t, v)
  
          # 使用torch.einsum函数进行高效的矩阵计算，实现图卷积操作
          x = torch.einsum('nkctv, kvw -> nctw', (x, A))
  
          # 确保输出tensor连续存储
          return x.contiguous()
  ```

  ​	总结来说，ST-GCN++ 结构结合了GCN和TCN的优势，在时空域上对骨骼关键点进行深度特征抽取和融合，以实现高效精准的动作识别。通过不断加深网络结构以及适时的特征降采样，模型能够在保持较高识别精度的同时，减少计算成本，适应骨骼动作识别的实际需求。

#### 5. ST-GCN++ 改进点

- **TCN（Temporal Convolutional Network）的优化**

  - 在ST-GCN++中，摒弃了原来使用单一的大kernel尺寸的1D卷积结构，转而采用多分支的时域卷积策略。这种方式不仅提升了网络对时序特征建模的能力，而且有效减少了计算量和参数量。

  ![image-20240426214607270](assets/image-20240426214607270.png)

- **GCN（Graph Convolutional Network）的改良**

  - 原始版的GCN使用预定义的系数矩阵与数据驱动产生的稀疏mask相乘得到系数矩阵A，通过A来融合不同关键点的特征。但由于这种方法仅限于相邻关键点间的连接，导致模型对关键点的建模能力受限。
  - 改进后的GCN首先使用预训练得到的系数矩阵A作为初始值，并在训练过程中不断调整和优化A。此外，还在GCN模块中加入了残差连接（residual structure），增强了网络的深度学习能力和性能。

- **数据预处理与超参数调优**

  - 在ST-GCN中，所有样本均会被zeropad（0填充）至统一的最大长度（例如300帧）。
  - 而在ST-GCN++中，对每个骨骼关键点的时间序列进行了规范化操作，包括减去首帧的中心点坐标并将骨架旋转到特定角度，以获取更为纯净的输入特征。
  - 在构建输入数据时，ST-GCN++采用了uniform sampling（均匀采样），将每个样本处理为长度为100帧的序列，此举有助于减少计算量，并增强了数据驱动的特性。
  - 在超参数设定方面，ST-GCN++采用了CosineAnnealing Scheduler策略，通过cos函数动态调整学习率。此外，还增大了权重衰减（large weight decay），以有效防止过拟合现象的发生。

- **基于骨骼的动作识别模型精度对比**

![image-20240426214712411](assets/image-20240426214712411.png)



### 6.缺点

- **扩展性问题**
  GCN在处理大规模图数据时扩展性较差，由于训练时需要访问训练和测试节点的所有邻接矩阵信息，导致其只能处理小规模或静态图数据。针对这一transductive性质，论文《GraphSAGE: Inductive Representation Learning on Large Graphs》提出了GraphSAGE方法，该方法旨在提升模型的扩展性和改善训练方法。GraphSAGE通过学习一个聚合器而非单独为每个节点生成表示，增强了模型的灵活性和泛化能力。尽管如此，GraphSAGE在层数增加时，节点采样数量随之呈指数增长，导致模型在每批次时间性能上的劣势，相较于GCN并不理想，这部分问题在Cluster-GCN等论文中有详细的探讨。

- **深度限制**
  实践中发现GCN在较浅的层次（如两层）效果最佳，增加网络深度会导致性能下降。这是由于过度平滑现象，即随着网络深度增加，节点特征逐渐趋于一致，丧失了区分性。虽然有研究如《DeepGCNs: Can GCNs Go as Deep as CNNs?》尝试通过引入残差连接（ResGCN）、密集连接（DenseGCN）和扩张卷积（Dilation）等技术缓解此问题，并成功将网络层数提升至56层，性能有所提升，但在根本上解决GCN的深度问题仍有待深入研究。另外，《Deep insights into Graph Convolutional Networks for Semi-supervised Learning》提供了对过度平滑问题的分析，《Representation learning on graphs with jumping knowledge networks》则通过在网络末尾构建一个能从所有层输出中选择特征的层聚合器来抑制噪声信息，试图构建深度更强的图神经网络。

- **非对称图处理**
  GCN不能直接处理非对称的有向图，因为其背后的数学推导需要用到拉普拉斯矩阵的特征分解，而这要求拉普拉斯矩阵必须是对称的。

- **权重分配固定**
  在同等邻域内，GCN对不同邻居节点分配相同的权重，这意味着它在处理空间信息相关性时的表达力有限，相比能够根据不同邻居重要性分配权重的GAT（Graph Attention Network）模型，在某些任务上表现不足。

#### 7.改进方案

- **残差结构与扩张卷积 - 图注意力网络GAT**
  GAT通过借鉴自注意力机制，解决了GCN无法根据节点重要性动态分配权重的问题。GAT不再假定邻居节点对中心节点的贡献相同或预先确定，而是使用注意力机制来确定邻居节点对当前节点的重要程度，从而聚合邻居信息。

- **邻接矩阵的探索 - 自适应GCN(AGCN)**
  AGCN通过引入自适应邻接矩阵的概念，利用残差图（基于节点对距离计算得到）来拓展原始图结构，进而探索和学习图拉普拉斯矩阵中未明确展现的隐藏结构关系。AGCN利用可学习的距离函数生成残差图邻接矩阵，使模型能够更好地捕捉图中节点间复杂的相互影响。



## 三. 学习总结

以下是对图卷积神经网络学习的主要收获和总结：

**1. 图卷积神经网络（GCN）产生的背景和作用**：传统CNN和RNN在处理不规则图结构数据时表现出局限性，GCN应运而生，它作为一种特征提取器，能够从图数据中自动提取节点特征和节点间的关系特征，从而用于节点分类、图分类、边预测等任务。

**2. GCN的工作原理与核心思想**：GCN通过利用节点间的连接信息来推导各个节点的特征，实现特征的聚合与传播。其中，基于频谱和基于空间的两类方法分别从谱域和空间域对图数据进行特征抽取，频谱方法侧重于图信号的频谱分析，而空间方法更关注于邻域聚合，后者因高效性、通用性和灵活性优势而在实际应用中更为广泛。

**3. GCN的局限性与改进方案**：

- **扩展性差**：GCN在训练时通常要求预先知道整个图结构，难以处理大规模动态图，GraphSage引入了学习聚合器的思想，实现了局部节点信息的批量学习，但存在节点采样数量随层数增加的问题，可以通过Cluster-GCN等方法优化。
- **深度限制**：GCN通常受限于较浅的网络结构，深层次会导致过度平滑问题，影响模型性能。研究者提出了诸如残差连接、跳跃式知识网络等方法来克服这一问题，例如DeepGCNs尝试通过ResGCN等结构加深网络层次并取得一定成果。
- **处理有向图的能力**：GCN在处理有向图时面临挑战，因为谱方法依赖于对称拉普拉斯矩阵，对此可通过转换为无向图或研发专门处理有向图的变种方法。
- **权重分配不灵活**：GCN对同阶邻域节点赋予相同的权重，限制了模型捕获空间信息相关性的能力。GAT（图注意力网络）通过引入注意力机制，允许为不同邻居节点指定不同的权重，从而改善模型性能。

**4. ST-GCN++的改进措施**：针对动作识别场景下的骨骼数据，ST-GCN++在网络结构、数据预处理和超参数设定等方面做出了多项改进，包括采用多分支时域卷积加强时序建模能力，训练过程动态更新GCN中的系数矩阵A，并加入残差结构，同时对输入数据进行归一化和均匀采样等预处理步骤，以及调整优化策略如CosineAnnealing Scheduler和增大权重衰减以防止过拟合。

​	

## 四. 后续学习规划



### **1. 深入探究图卷积神经网络的深层架构**：

- 继续钻研如何有效解决GCN在加深网络层次时出现的过度平滑问题，研究现有解决方案如残差连接（ResGCN）、跳跃连接（Jumping Knowledge Networks）等，并尝试寻找新的深度学习结构，以实现在保持甚至提高模型性能的同时，构建更深的图卷积网络。

**2. 拓展图神经网络的应用边界**：

- 研究如何将现有的GCN改进方法应用于更大规模、更复杂的图数据集，尤其是动态图的处理。这可能涉及到对GraphSAGE等具备扩展性方法的深入理解和实践，以及对分布式训练、子图采样技术的进一步研究。

**3. 探索新型图卷积机制**：

- 学习并实践图注意力网络（GAT）等创新模型，理解并优化注意力机制在图数据上的工作原理，提升模型在处理不同类型节点关联权重时的灵活性和准确性。

**4. 面向骨骼识别的具体任务改进**：

- 在ST-GCN++的基础上，探索更加高效的时空建模方法，结合更多的先验知识，比如人体关节运动规律、生物力学特性等，优化骨骼数据的预处理和特征表示。
- 研究如何利用自适应邻接矩阵（AGCN）等技术来挖掘潜在的隐藏结构关系，进一步提升骨骼动作识别的准确率。

**5. 交叉学科和领域研究**：

- 尝试将图卷积神经网络与其他领域知识结合，比如物理模拟、强化学习等，以应对跨领域的图结构数据分析任务。

**6. 实验验证与实战项目**：

- 设计和实施一系列实验项目，将上述理论知识应用到实际的骨骼识别或其他图数据相关的任务中，通过不断的迭代和优化，积累实践经验，形成可用于实际产品或服务的技术方案。

**7. 学术跟进与文献阅读**：

- 持续跟踪最新的图神经网络研究成果，定期阅读和总结相关的学术论文，把握最新趋势和技术进展。

**8. 代码实现与开源贡献**：

- 将学习过程中的理论知识转化为代码实现，通过GitHub等平台分享自己的研究成果和实验代码，积极参与开源社区，与其他研究者交流互动，共同推动图卷积神经网络的发展。
